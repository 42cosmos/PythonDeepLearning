# 5.3.4.     선형 회귀와 로지스틱 회귀

**딥러닝을** **이해하기** **위해** **가장** **기본적인** **두가지** **수학** **계산** **원리를** **반드시** **이해해야** **합니다.** **그** **두가지가** **선형** **회귀와** **로지스틱** **회귀입니다.** **통계학에서,** **회귀** **분석\(regression analysis\)은** **관찰된** **연속형** **변수들에** **대해** **두** **변수** **사이의** **모형을** **구한뒤** **적합도를** **측정해** **내는** **분석** **방법입니다.** 통계학에서, 회귀분석이란 관찰된 연속형 변수들에 대해 두 변수 사이의 모형을 구한뒤 적합도를 측정해 내는 분석 방법입니다. 회귀 분석\(regression analysis\)은 입력 자료\(독립 변수\) x 와 이에 대응하는 출력 자료\(종속 변수\) y 간의 관계를 정량화 하기 위한 작업입니다.

**회귀분석은** **시간에** **따라** **변화하는** **데이터나** **어떤** **영향,** **가설적** **실험,** **인과** **관계의** **모델링등의** **통계적** **예측에** **이용될** **수** **있습니다.**

**1\)    선형 회귀\(Linear Regression\)**

**선형** **회귀** **분석**은 종속 변수 y와 한 개 이상의 독립 변수 X와의 선형 상관 관계를 모델링하는 회귀분석 기법입니다. 선형 회귀 분석은 머신러닝의 기초로서 다양한 분야에 적용할 수 있습니다. 예를들어 몸무게와 나이 데이터로 고혈압과의 상관 관계를 구합니다.거나, 집의 평수와 건축 년도등의 데이터로 집 값을 예측하는 분석 시스템에 사용됩니다. 일반적으로 선형 회귀는 다음과 같은 방정식과 그림으로 표현됩니다.

위의 선형 회귀 방정식을 보면 여러 반복을 통해 slope\(W\)와 bias\(b\)의 기울기를 학습하는 그래프를 작성하는 것으로 시작합니다. 회귀분석을 한다는 것은 x 변수, y 변수를 지정하고 통계 툴이 최소제곱법을 이용해 회귀식 y = wx + b에서 w와 b를 구하는 과정을 말합니다. 회귀식에서 w를 회귀계수, b를 y절편이라고 부릅니다. w는 가중치의 역할을 하기 때문에 x가 y에 얼마나 영향을 주는지 그 크기와 방향을 알 수 있게 해주고, b는 절편의 역할을 하기 때문에 y = wx 라는 회귀선을 얼마나 위 또는 아래로 평행이동 시키는지를 정합니다. 여기서 y는 종속 변수이고 x는 독립 변수입니다. 따라서 선형 회귀 분석에서 변수 x의 변화는 변수 y의 변화를 일으키므로 기울기 w과 절편 값 b의 적절한 값을 찾아 모든 x에 대해 y의 정확한 예측 값을 얻는 것이 목표입니다. 각 반복에서 실제 입력 y와 예측된 y를 비교하여 차이를 줄이는 것을 목표로 합니다. 즉 선형 회귀 분석이란 x의 입력이 우리에게 원하는 y를 제공하도록 W와 b를 수정하여 최상의 적합한 선을 찾는 것입니다.

잔차란 관측값의 y와 예측값의 y 간의 차이를 잔차라고 하는데 예를 들어 A\(1, 4\)과 B\(2, 3\)라는 2개의 점이 있다고 하고, 회귀식이 y = 2x + 1 이라면 점 A의 관측값 y는 4, 예측값 y는 3이고 점 B의 관측값 y는 3, 예측값 y는 5입니다. 이때 A의 잔차는 4 - 3 = 1이고 B의 잔차는 3 - 5 = -2 가 됩니다. 최소제곱법은 잔차의 제곱의 합이 최소가 되도록 하는 직선을 회귀선으로 한다는 것을 의미합니다. 그렇다면 위의 예에서 잔차의 제곱의 합은 5입니다. 이 방법은 Cost\(오차\)를 구하는데 효과적입니다. 회귀식을 바꿔가면서 잔차의 제곱의 합이 최소가 되게 하는 직선을 찾는 것이 선형 회귀분석입니다.

다음의 예제를 실습해 보면서 선형회귀를 이해해 봅시다.

Generating Dataset

**def** generate\_dataset\(\):  
  x\_batch = np.linspace\(0, 2, 100\)  
  y\_batch = 1.5 \* x\_batch + np.random.randn\(\*x\_batch.shape\) \* 0.2 + 0.5  
  **return** x\_batch, y\_batch

**우선 x와 y라는 데이터 세트를 생성합니다. x와 y의 각 값을 그래프상의 점으로 생각할 수 있습니다.**

**입력 x\_batch에** **np.linspace는 numpy를 사용하여 0과 2 사이의 값으로 100개의 점을 생성하고 균등하게 분산 시킨다. W\(가중치\) 값과 b\(바이어스\) 값을 지정 해야 하는데 임의로 W = 1.5, b = 0.5로 지정합니다. 함수 y의 결과 값은 np.random.randn\(\)을 사용하여 1.5\(W\)의 그래디언트와 임의의 그래디언트를 갖도록 y를 생성합니다.**

**파이썬에서 Asterisk\(\*\)는 다음과 같은 상황에서 사용되는데 크게 4가지의 경우가 있습니다.**

**-**       **곱셈 및 거듭제곱 연산으로 사용할 때**

**-**       **리스트형 컨테이너 타입의 데이터를 반복 확장하고자 할 때**

**-**       **가변인자 \(Variadic Arguments\)를 사용하고자 할 때**

**-**       **컨테이너 타입의 데이터를 Unpacking 할 때**

**위에서 사용된** np.random.randn\(\*x\_batch.shape\)에서 \*의미는 가변 인자의 의미입니다. 즉 100개의 난수를 발생시키라는 의미입니다.

**리턴값은 numpy 배열 x\_batch와 y\_batch입니다.**

**생성되는** **데이터가** **궁금하다면** **다음** **코드를** **실행** **해** **봅니다.**

**import** numpy **as** np  
 **import** tensorflow **as** tf  
 **import** matplotlib.pyplot **as** plt  
  
 **def** generate\_dataset\(\):  
  x\_batch = np.linspace\(0, 2, 100\)  
  y\_batch = 1.5 \* x\_batch + np.random.randn\(\*x\_batch.shape\) \* 0.2 + 0.5  
  **return** x\_batch, y\_batch  
  
  
 x\_batch, y\_batch = generate\_dataset\(\)  
 plt.scatter\(x\_batch, y\_batch\)  
 plt.show\(\)

Constructing the TensorFlow Graph

**def** linear\_regression\(\):  
     x = tf.placeholder\(tf.float32, shape=\(**None**,\), name=**'x'**\)  
     y = tf.placeholder\(tf.float32, shape=\(**None**,\), name=**'y'**\)  
  
     **with** tf.variable\_scope\(**'lreg'**\) **as** scope:  
         w = tf.Variable\(np.random.normal\(\), name=**'W'**\)  
         b = tf.Variable\(np.random.normal\(\), name=**'b'**\)  
         y\_pred = tf.add\(tf.multiply\(w, x\), b\)  
         loss = tf.reduce\_mean\(tf.square\(y\_pred - y\)\)  
  
     **return** x, y, y\_pred, loss

**다음으로** **W와** **b를** **계산하는** **데** **사용되는** **TensorFlow** graph**를** **linear\_regression\(\)** **함수에서** **만듭니다.** **수식** **y = Wx + b에서** **x와** **y는** **TensorFlow의** placeholder로 **표현된** **노드입니다.**

**tf.placeholder의** **첫** **번째** **인수에서** **데이터** **유형을** placeholder**의** **공통** **데이터** **유형** **인** **float32로** **정의합니다.** **두** **번째** **인수는** placeholder**의** **shape=\(None,\)** **으로** **설정하여** training time **중에** **결정하도록** **합니다.** **세** **번째** **인수는** placeholder**의** **이름을** **w, b로** **설정합니다.**

**with** tf.variable\_scope\(**'lreg'**\) **as** scope:

**이** **행은** **w, b** **변수에** **대한** **변수** **범위\(Variable scope\)를** **정의합니다.** **즉,** **변수** **범위\(Variable scope\)를** **사용하면** **이름** **충돌을** **피하기** **위해** **변수의** **이름을** **계층** **구조로** **지정할** **수** **있습니다.**

**변수가** **정의되더라도** **해당** **값을** **사용하여** **연산을** **실행하려면** **먼저** **변수를** **명시적으로** **초기화해야합니다. W가** **실제로하는** **일은** **우리가** **가장** **잘** **맞는** **선의** **그라디언트를** **찾는** **것입니다.** **이전** **챕터의** Gradient Descent**을** **확인해** **보십시오.** **선형** **회귀** **분석에서** **최적의** **경사도\(**Gradient**\)를** **찾는** **것이** **주** **목적이므로** **W를** **초기화하는** **위치에** **관계없이** **Cost** **함수가** **항상** **최소** **Cost** **값** **하나를** **산출해야** **합니다.**

**b = tf.Variable \(np.random.normal \(\), name = 'b'\)**

**W가** **아닌** **bias b** **를** **training** **시켜야** **합니다.**

**y\_pred = tf.add \(tf.multiply \(w, x\), b\)**

**x, y** **및** **W를** **개별적으로** **정의한** **후에** **이제** **이들을** **결합할** **준비가되었습니다.** **수식** **y = Wx + b을** **구현하기** **위해** **tf.add** **와** **tf.multiply를** **사용하여** **정의합니다. y\_pred는** **예측된** **y** **값을** **나타냅니다.**

**loss = tf.reduce\_mean \(tf.square \(y\_pred - y\)\)**

**y\_pred를** **계산한** **후** **예측된** **y가** **생성된** **y와** **얼마나** **멀리** **떨어져** **있는지** **알기** **위해** **차이를** **계산하는** **손실\(loss, cost\)** **함수를** **설계** **해야합니다.** **여기서는** **MSE \(Mean Squared Error\) L2** **손실** **함수를** **"** **scoring mechanism "으로** **선택했습니다.**

**MSE의** **구현을** **이해하기** **위해** **먼저** **y\_pred - y를** **사용하여** **y\_pred와** **y에** **대한** **100** **개의** **점** **사이의** **차이를** **구하고** **그것들을** **제곱하여** **\(tf.square\)** **그들의** **차이를** **증폭시켜** **차이를** **크게** **만듭니다.**

**tf.reduce\_mean을** **사용하여** **100** **개의** **모든** **값의** **평균을** **찾고** **이를** **손실로** **정합니다.**

Computing the Graph

**이제** **전체** **프로그램** **소스** **코드를** **확인해** **봅시다.**

**import** numpy **as** np  
 **import** tensorflow **as** tf  
 **import** matplotlib.pyplot **as** plt  
  
 **def** generate\_dataset\(\):  
  x\_batch = np.linspace\(0, 2, 100\)  
  y\_batch = 1.5 \* x\_batch + np.random.randn\(\*x\_batch.shape\) \* 0.2 + 0.5  
  **return** x\_batch, y\_batch  
  
  
 **def** linear\_regression\(\):  
     x = tf.placeholder\(tf.float32, shape=\(**None**,\), name=**'x'**\)  
     y = tf.placeholder\(tf.float32, shape=\(**None**,\), name=**'y'**\)  
  
     **with** tf.variable\_scope\(**'lreg'**\) **as** scope:  
         w = tf.Variable\(np.random.normal\(\), name=**'W'**\)  
         b = tf.Variable\(np.random.normal\(\), name=**'b'**\)  
         y\_pred = tf.add\(tf.multiply\(w, x\), b\)  
         loss = tf.reduce\_mean\(tf.square\(y\_pred - y\)\)  
  
     **return** x, y, y\_pred, loss  
  
  
 **def** run\(\):  
     x\_batch, y\_batch = generate\_dataset\(\)  
     x, y, y\_pred, loss = linear\_regression\(\)  
  
     optimizer = tf.train.GradientDescentOptimizer\(0.1\)  
     train\_op = optimizer.minimize\(loss\)  
  
     **with** tf.Session\(\) **as** session:  
         session.run\(tf.global\_variables\_initializer\(\)\)  
         feed\_dict = {x: x\_batch, y: y\_batch}  
  
         **for** i **in** range\(30\):  
             session.run\(train\_op, feed\_dict\)  
             print\(i, **"loss:"**, loss.eval\(feed\_dict\)\)  
  
         print\(**'Predicting'**\)  
         y\_pred\_batch = session.run\(y\_pred, {x: x\_batch}\)  
  
     plt.scatter\(x\_batch, y\_batch\)  
     plt.plot\(x\_batch, y\_pred\_batch, color=**'red'**\)  
     plt.xlim\(0, 2\)  
     plt.ylim\(0, 2\)  
     plt.show\(\)  
     \#plt.savefig\('plot.png'\)  
  
  
 **if** \_\_name\_\_ == **"\_\_main\_\_"**:  
     run\(\)

generate\_dataset \(\) 및 linear\_regression \(\)을 사용하여 이제 프로그램을 실행하고 최적의 gradient W 및 bias b를 찾을 준비가되었습니다.

x\_batch, y\_batch = generate\_dataset\(\)  
 x, y, y\_pred, loss = linear\_regression\(\)

optimizer = tf.train.GradientDescentOptimizer\(0.1\)  
 train\_op = optimizer.minimize\(loss\)

손실\(loss, cost\)를 최소화하기 위해 optimiser를 정의합니다. 선택할 수있는 몇 가지 최적화 도구중에 Gradient Descent 알고리즘을 선택하고 학습 속도를 0.1로 설정했습니다. GradientDescentOptimizer의 인수는 사용할 learning rate입니다.

간단히 말해서 optimiser의 임무는 cost를 최소화하는 것입니다. 실행될 때마다 최적 솔루션의 방향으로 학습 가능한 변수 \(W 및 b\)를 업데이트함으로써 동작 합니다.

Minimize\(\) 함수를 호출하면 그라디언트가 계산되어 변수에 적용됩니다. 이는 기본 동작이며 var\_list 인수를 사용하여 자유롭게 변경할 수 있습니다.

`with tf.Session() as session:`

`session.run(`[tf.global\_variables\_initializer\(\)](https://www.tensorflow.org/api_docs/python/tf/initializers/global_variables)`)`

그런 다음 모든 변수를 초기화하여 첫 번째 세션을 시작합니다.

`feed_dict = {x: x_batch, y: y_batch}`

실제 TensorFlow의 session.run 은 다음과 같은 인수들을 받을 수 있습니다.

run\(  
     fetches,  
     feed\_dict=None,  
     options=None,  
     run\_metadata=None  
 \)

실제 실행이 되는 시점의 sess.run\(\)에서 feed\_dict 인수로 데이터를 feed 하여 사용하게 됩니다. feed\_dict 인수를 사용하면 그래프의 텐서 값 \(스칼라, 문자열, 목록, 숫자 배열 또는 tf.placeholder, 예 : x 및 y\)을 무시할 수 있습니다. x와 y는 placeholder이고 x\_batch와 y\_batch는 session이 실행 되는 중에 placeholder를 채울 준비가 된 값입니다.

fetches는 텐서플로우 graph의 operation을 session에서 실행 하기 위해 넘겨주는 opration, tensor 등이 될 수 있습니다.

`for i in range(30):`

변수를 초기화하고 feed\_dict를 사용하여 placeholder에 대한 값을 준비한 후 이제 스크립트의 핵심 부분으로 이동하여 weight\(W\)와 bias\(b\)를 train 하려는 횟수를 정의합니다.

하나의 전체 사이클에서 훈련 데이터 \(x 및 y\)를 통과하는 횟수를 epoch 또는 training step 라고도합니다. 하나의 전체주기는 하나의 feed forward 및 하나의 back propagation 으로 정의됩니다.

Feedforward neural network 및 Backpropagation에 대해서는 위키피디아를 참고하기 바랍니다.

Feedforward neural network: [https://en.wikipedia.org/wiki/Backpropagation](https://en.wikipedia.org/wiki/Backpropagation)

Backpropagation: [https://en.wikipedia.org/wiki/Feedforward\_neural\_network](https://en.wikipedia.org/wiki/Feedforward_neural_network)

feedforward 중에 x, w 및 b의 값을 전달하여 예측된 y를 얻습니다. 이것은 숫자로 표현되는 loss\(cost\)를 계산한 것입니다.

이 그래프의 목적은 optimiser가 트레이닝 가능한 변수 \(W 및 b\)를 "조정"하기 위해 backpropagation를 수행하여 다음 feedforward를 수행할 때 손실\(loss\)를 낮추는 것입니다.

이 코드에서는 30번 학습을 시키지만 자유롭게 변경할 수 있습니다. 이값이 커질수록 손실\(loss\)값이 작아지는 것을 확인 할 수 있습니다.

session.run\(train\_op, feed\_dict\)

이제 session을 실행합니다. Operation 은 train\_op이고 제공되는 데이터는 feed\_dict에 들어 있습니다.

`print(i, “loss:”, loss.eval(feed_dict))`

각 training step 마다 손실\(loss\)을 화면에 출력합니다. 손실 값은 loss.eval\(\) 및 feed\_dict를 인수로 사용하여 계산됩니다. TensorFlow에는 그래프 목록을 평가하는 두 가지 방법이 있습니다. 변수 목록의 Session.run과 Tensor.eval입니다. Tensor.eval\(\)을 호출하는 것은 tf.get\_default\_session\(\).run \(tensor\)을 호출하는 것과 같습니다. 그러나 eval\(\)은 현재 단계에서의 값을 가져올 수 있다는 것입니다.

print\('Predicting'\)  
 y\_pred\_batch = session.run\(y\_pred, {x : x\_batch}\)

30 번의 학습 후에, 처음 값과 달라진 추론\(Inference\)된 W와 b를 가지게 됩니다. 트레이닝과 마찬가지로 추론은 session.run\(\)을 사용하여 동일한 그래프로 수행할 수 있지만 이번에는 페치가 train\_op 대신 y\_pred가되고 x를 입력하면 됩니다. W와 b는 이미 훈련되었고 예측된 y는 x로 계산될 수 있기 때문에 이렇게 수행합니다.

y\_pred 를 구하는 tf.add\(tf.multiply\(w, x\), b\)에 y가 없다는 것을 생각 하십시오.

지금까지 3 개의 session.run\(\)을 선언했는데 다시 한번 session.run\(\)을 어떻게 사용했는지 정리해 보겠습니다. 처음으로 우리가 한 일은 우리의 변수를 초기화하는 것이 었습니다. 두 번째는 feed\_dict를 전달하고 세 번째는 예측을 실행하는 것입니다.

plt.scatter\(x\_batch, y\_batch\)  
 plt.plot\(x\_batch, y\_pred\_batch, color='red'\)  
 plt.xlim\(0, 2\)  
 plt.ylim\(0, 2\)

plt.show\(\)  
 \#plt.savefig\('plot.png'\)

**생성된** **x\_batch** **및** **y\_batch와** **예측된** **선** **\(x\_batch** **및** **y\_pred\_batch** **포함\)으로** **차트를** **그립니다**

**학습이** **반복될수록** **loss** **값이** **줄어** **드는** **것을** **확인** **할** **수** **있습니다.**

**20 loss: 0.043225072**

**21 loss: 0.043008752**

**22 loss: 0.042805683**

**23 loss: 0.04261506**

**24 loss: 0.042436123**

**25 loss: 0.042268157**

**26 loss: 0.04211048**

**27 loss: 0.041962486**

**28 loss: 0.041823555**

**29 loss: 0.04169314**

**Predicting**

그러나 실생활에서 모든 원인과 결과가 직선에 그래프에 알맞게 나타나지는 않습니다. 그래서 정확도가 떨어질 수 있습니다. 이 부분을 보완할 수 있는 것이 로지스틱 회귀입니다.

**2\)   로지스틱 회귀\(Logistic Regression\)**

로지스틱 회귀분석이란 분석하고자 하는 대상들이 두 집단 혹은 그 이상의 집단으로 나누어진 경우에 개별 관측치들이 어느 집단에 분류될 수 있는가를 분석하고 이를 예측하는 모형을 개발하는데 사용되는 통계기법입니다. **예측변수** **세트의** **값을** **기준으로** **결정되는** **특성이나** **결과가** **있는지** **여부를** **예측하려는** **상황에서** **유용합니다.** **예를** **들어** **비흡연가들보다** **흡연가들에게** **관상동맥성심장병** **가** **발병할** **가능성이** **얼마나** **더** **많은지를** **예측하려면** **로지스틱** **회귀** **분석을** **사용해야** **합니다.**

Logistic Regression Model \([http://dataaspirant.com/2017/03/02/how-logistic-regression-model-works/](http://dataaspirant.com/2017/03/02/how-logistic-regression-model-works/)\)

위의 그림에서 입력은 X1,X2,X3 등 다양하고 가중치도 θ1,θ2,θ3 다양하지만 출력은 2가지 뿐입니다. 로지스틱 회귀는 매우 효율적인 확률 계산 메커니즘입니다.

로지스틱 회귀 분석의 결과는 이분법적 변수로 측정됩니다. 이것은 독립 변수들의 집합에서 이진 결과 \(1/0, 예/아니오, 참/거짓\)를 예측하는 데 사용됩니다. 이진형 결과를 나타 내기 위해 더미 변수를 사용합니다. 또한, 결과 변수가 범주 형 일 때 선형 회귀의 특수한 경우로 로지스틱 회귀를 생각할 수 있습니다. 여기서 우리는 확률 로그를 종속 변수로 사용합니다. 간단히 말하면, 데이터를 로짓 함수에 맞추어 이벤트의 발생 확률을 예측합니다.

전자 메일이 스팸인지 아닌지를 분류해야하는 시나리오를 생각해봅시다. 이 문제에 대해 선형 회귀 분석을 사용하면 분류를 수행할 기준을 설정해야 할 필요가 있습니다. 실제로 메일이 악성인지 아닌지에 대한 기준값을 연속값으로 정하고 분류하는 것은 심각한 결과를 초래할 수 있다고 합니다. 이러한 예에서 선형 회귀는 분류 문제에 적합하지 않다고 추측할 수 있습니다.

시그모이드 함수는 바이너리 로지스틱 회귀를 할 때 사용됩니다. 즉 0, 1 두가지의 결과값으로 분류할때 굉장히 유용합니다. 선형회귀는 직선모양의 그래프를 만들어 분류하였는데 로지스틱 회귀는 시그모이드 함수를 사용하여 S자 형태를 띄고 있기 때문에 비교적 더 정확한 예측이 가능합니다.

Sigmoid의 표현은 아래와 같습니다.

`z`가 로지스틱 회귀를 사용하여 학습된 모델의 선형 레이어의 출력을 나타내는 경우 sigmoid\(z\)는 0과 1 사이의 값\(확률\)을 생성합니다. 수학적 표현으로는 왼쪽과 같습니다.

여기서

-       y'는 특정 예에 관한 로지스틱 회귀 모델의 출력입니다.

-       z = b + w1x1 + w2x2 + ... wNxN

-       w 값은 모델의 학습된 가중치이고, b는 편향입니다.

-       x 값은 특정 예에 대한 특성 값입니다.

z는 z를 '1' 라벨\(예: '스팸'\)의 확률을 '0' 라벨\(예: '스팸 아님'\)의 확률로 나눈 값의 로그로 정의할 수 있는 시그모이드 상태의 역수이므로 로그 오즈\(log-odds\)라고도 합니다.

로그 오즈는 어떤 이벤트가 일어날 가능성의 로그입니다.

이벤트가 이진 확률을 의미하는 경우의 **가능성**은 성공 확률\(p\) 대 실패 확률\(1-p\)의 비율을 의미합니다. 특정 이벤트의 성공 확률이 90%, 실패 확률이 10%라고 가정해 보겠습니다. 이 경우의 가능성은 다음과 같이 계산됩니다.

가능성=p\(1-p\)=.9.1=9

로그 오즈는 가능성의 로그입니다. 관례에 따르면 '로그'란 자연 로그를 나타내지만 로그의 밑은 사실 1보다 큰 임의의 수가 될 수 있습니다. 관례를 따르면, 앞에서 든 예의 로그 오즈는 다음과 같이 나타낼 수 있습니다.

로그 오즈=ln\(9\) =2.2

로그 오즈는 [**시그모이드 함수**](https://developers.google.com/machine-learning/crash-course/glossary?hl=ko#sigmoid_function)의 역함수입니다.

다음과 같은 편향과 가중치를 학습한 특성이 세 개인 로지스틱 회귀 모델이 있다고 가정합니다.

b = 1, w1 = 2, w2 = -1, w3 = 5

또한 지정된 예의 특성 값이 다음과 같다고 가정합니다.

x1 = 0, x2 = 10, x3 = 2

따라서 로그 오즈는 b+w1x1+w2x2+w3x3 이며, 다음과 같습니다.

  \(1\) + \(2\)\(0\) + \(-1\)\(10\) + \(5\)\(2\) = 1

결과적으로 이 특정 예의 로지스틱 회귀 예측값은 0.731입니다.

승산\(Odds\)이란 임의의 사건 A가 발생하지 않을 확률 대비 일어날 확률의 비율을 뜻하는 개념입니다. 아래와 같은 식으로 쓸 수가 있습니다.

만약 P\(A\)가 1에 가까울 수록 승산은 치솟을 겁니다. 반대로 P\(A\)가 0이라면 0이 될 겁니다. 바꿔 말하면 승산이 커질수록 사건 A가 발생할 확률이 커진다고 이해해도 될 겁니다. 

**로지스틱** **회귀는** **결과에** **따라** **다음과** **같이** **분류됩니다.**

**-**       **이항 로지스틱 회귀\(Binary Logistic Regression\): 두 가지 결과만 있는 경우 \(예: 스팸 여부\)**

**-**       **다항 로지스틱 회귀 분석\(Multinomial Logistic Regression\):** **예측하고자 하는 분류가 두 개가 아니라 여러 개가 될 수 있는 경우 \(예: 어느 음식이 더 많이 먹는 지 예측 \(Veg, Non-Veg, Vegan\)\)**

**-**       **순서형 로지스틱 회귀\(Ordinal Logistic Regression\): 순서가 있는 3 개 이상의 분류. \(예: 1에서 5까지의 영화 등급\)**

**이항 로지스틱 회귀에서** **데이터가** **속한** **분류를** **예측하기** **위해** **임계** **값을** **설정할** **수** **있습니다.** **이** **임계치에** **기초하여,** **획득된** **추정** **확률로** **분류됩니다.** **의사** **결정** **경계\(Decision Boundary\)는** **선형** **또는** **비선형** **일** **수** **있습니다.** **복잡한** **의사** **결정** **경계를** **얻기** **위해** **여러** **개의** **이항** **로지스틱이** **필요합니다.** **즉** **다항** **로지스틱** **회귀분석이** **필요** **합니다.**

softmax는 데이터를 2개 이상의 그룹으로 나누기 위해 binary classification을 확장한 모델입니다. 소프트맥스는 다항 로지스틱 회귀 분석중 하나입니다.  softmax는 binary classification을 여러 번 결합한 결과입니다. 예측 결과가 A, B, C 중의 하나가 되어야 한다면, 동일한 x에 대해 A가 될 확률, B가 될 확률, C가 될 확률을 모두 구해야 한다는 뜻입니다.

**이제** **소프트맥스를** **사용해서** **MNIST를** **이용해** **숫자** **이미지를** **인식하는** **모델을** **구현하고** **테스트해봅시다.  MNIST에** **대해서는** **이전** **설명을** **참고하십시오.**

**소프트맥스** **회귀는** **들어온** **값이** **어떤** **분류인지** **구분해주는** **알고리즘이다.** **로지스틱** **회귀는** **두** **가지로만** **분류가** **가능하지만,** **소프트맥스** **회귀는** **n** **개의** **분류로** **구분이** **가능합니다.**

**소프트맥스로** **분류를** **할때, x라는** **값이** **들어** **왔을때,** **분류를** **하려고** **가정했을때,** **모델에서** **사용하는** **가설은** **다음과** **같습니다.** 

**y = softmax \(W\*x + b\)**

**W는** **weight,** **그리고** **b는** **bias** **값입니다. y는** **최종적으로** **10개의** **숫자를** **감별하는** **결과가** **나와야** **하기** **때문에,** **크기가** **10인** **행렬이** **되고, 10개의** **결과를** **만들기** **위해서** **W역시** **10개가** **되어야** **하며,** **이미지** **하나는** **784개의** **숫자로** **되어** **있기** **때문에, 10개의** **값을** **각각** **784개의** **숫자에** **적용해야** **하기** **때문에, W는** **784x10** **행렬이** **됩니다.** **그리고, b** **는** **10개의** **값에** **각각** **더하는** **값이기** **때문에,** **크기가** **10인** **행렬이** **됩니다.**

**이를** **텐서플로우** **코드로** **표현하면** **다음과** **같습니다.**

**x = tf.placeholder\(tf.float32, \[None, 784\]\)**

**W = tf.Variable\(tf.zeros\(\[784, 10\]\)\)**

**b = tf.Variable\(tf.zeros\(\[10\]\)\)**

**k = tf.matmul\(x, W\) + b**

**y = tf.nn.softmax\(k\)**

**우리가** **구하고자** **하는** **값은** **x** **값으로** **학습을** **시켜서** **0~9를** **가장** **잘** **구별해내는** **W와** **b의** **값을** **찾는** **일입니다.**

**x의** **데이타는** **총** **55000개로, 55000x784** **행렬이** **되고, W는** **784x10** **행렬이다.** **이** **둘을** **곱하면, 55000x10** **행렬이** **되는데, b는** **1x10** **행렬로** **차원이** **달라서** **합이** **되지** **않는다.**

**텐서플로우와** **파이썬에서는** **이렇게** **차원이** **다른** **행렬을** **큰** **행렬의** **크기로** **늘려주는** **기능이** **있는데,** **이를** **브로드캐스팅이라고** **합니다.** **브로드** **캐스팅에** **의해서** **b는** **55000x10** **사이즈로** **자동으로** **늘어나고** **각** **행에는** **첫행과** **같은** **데이타들로** **채워지게** **됩니다.**

**소프트맥스** **알고리즘을** **이해하고** **사용해도** **좋지만,** **텐서플로우에는** **이미** **tf.nn.softmax** **라는** **함수로** **만들어져** **있고,** **대부분** **많이** **알려진** **머신러닝** **모델들은** **샘플들이** **많이** **있기** **때문에,** **대략적인** **원리만** **이해하고** **가져다** **쓰는** **것을** **권장합니다.** **보통** **모델을** **다** **이해하려고** **하다가** **수학에서** **부딪혀서** **포기하는** **경우가** **많은데,** **디테일한** **모델을** **이해하기** **힘들면,** **그냥** **함수나** **예제코드를** **가져다** **쓰는** **방법으로** **접근하자.** **우리가** **일반적인** **프로그래밍에서도** **해쉬테이블이나** **트리와** **같은** **자료구조에** **대해서** **대략적인** **개념만** **이해하고** **미리** **정의된** **라이브러리를** **사용하지** **직접** **해쉬** **테이블등을** **구현하는** **경우는** **드물다.**

**코스트\(비용\) 함수**

**이** **소프트맥스** **함수에** **대한** **코스트** **함수는** **크로스엔트로피** **\(Cross entropy\)** **함수의** **평균을** **이용하는데,** **복잡한** **산식** **없이** **그냥** **외워서** **쓰자.** **다행이도** **크로스엔트로피** **함수역시** **함수로** **구현이** **되어있다.**

**Cost = tf.reduce\_mean\(tf.nn.softmax\_cross\_entropy\_with\_logits\(tf.matmul\(x, W\) + b, y\_\)\)**

**가설에** **의해** **계산된** **값** **y를** **넣지** **않고** **tf.matmul\(x, W\) + b** **를** **넣은** **이유는  tf.nn.softmax\_cross\_entropy\_with\_logits** **함수** **자체가** **softmax를** **포함하기** **때문이다.**

**y\_은** **학습을** **위해서** **입력된** **값이다.**

자 그럼 학습을 위한 전체 코드를 보자. 이 예제 코드는 [https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/2\_BasicModels/logistic\_regression.py](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/2_BasicModels/logistic_regression.py) 을 발췌하였다.

**import** tensorflow **as** tf  
  
 \# Import MNIST data  
 **from** tensorflow.examples.tutorials.mnist **import** input\_data  
 mnist = input\_data.read\_data\_sets\(**"/tmp/data/"**, one\_hot=**True**\)  
  
 \# Parameters  
 learning\_rate = 0.1  
  
 \# tf Graph Input  
 x = tf.placeholder\(tf.float32, \[**None**, 784\]\) \# mnist data image of shape 28\*28=784  
 y = tf.placeholder\(tf.float32, \[**None**, 10\]\) \# 0-9 digits recognition =&gt; 10 classes  
  
 \# Set model weights  
 W = tf.Variable\(tf.zeros\(\[784, 10\]\)\)  
 b = tf.Variable\(tf.zeros\(\[10\]\)\)  
  
 \# Construct model  
 pred = tf.nn.softmax\(tf.matmul\(x, W\) + b\) \# Softmax  
  
 \# Minimize error using cross entropy  
 cost = tf.reduce\_mean\(-tf.reduce\_sum\(y\*tf.log\(pred\), reduction\_indices=1\)\)  
  
 \# Gradient Descent  
 optimizer = tf.train.GradientDescentOptimizer\(learning\_rate\).minimize\(cost\)  
  
 \# Initialize the variables \(i.e. assign their default value\)  
 init = tf.global\_variables\_initializer\(\)  
  
 \# Start training  
 **with** tf.Session\(\) **as** sess:  
     \# Run the initializer  
     sess.run\(init\)  
  
     \# Training cycle  
     **for** epoch **in** range\(100\):    \# 100번씩, 전체 데이타에서 100개씩 뽑아서 트레이닝을 함.  
         avg\_cost = 0.  
         total\_batch = int\(mnist.train.num\_examples/100\)  
         \# Loop over all batches  
         **for** i **in** range\(total\_batch\):  
             batch\_xs, batch\_ys = mnist.train.next\_batch\(100\)  
             \# Run optimization op \(backprop\) and cost op \(to get loss value\)  
             \_, c = sess.run\(\[optimizer, cost\], feed\_dict={x: batch\_xs, y: batch\_ys}\)  
             \# Compute average loss  
             avg\_cost += c / total\_batch  
         \# Display logs per epoch step  
         **if** \(epoch+1\) % 10 == 0:  
             print\(**"Epoch:"**, **'%04d'** % \(epoch+1\), **"cost="**, **"{:.9f}"**.format\(avg\_cost\)\)  
  
     print\(**"Optimization Finished!"**\)  
     print\(**'b is '**, sess.run\(b\)\)  
     print\(**'W is'**, sess.run\(W\)\)  
  
     \# Test model  
     correct\_prediction = tf.equal\(tf.argmax\(pred, 1\), tf.argmax\(y, 1\)\)  
     \# Calculate accuracy  
     accuracy = tf.reduce\_mean\(tf.cast\(correct\_prediction, tf.float32\)\)  
     print\(**"Accuracy:"**, accuracy.eval\({x: mnist.test.images, y: mnist.test.labels}\)\)

코드를 세부적으로 설명하면 다음과 같습니다.

**import** tensorflow **as** tf  
  
 \# Import MNIST data  
 **from** tensorflow.examples.tutorials.mnist **import** input\_data  
 mnist = input\_data.read\_data\_sets\(**"/tmp/data/"**, one\_hot=**True**\)

앞에서 데이타에 대해서 설명한것과 같이 데이타를 로딩하는 부분이다. read\_data\_sets에 들어가 있는 디렉토리는 샘플데이타를 온라인에서 다운 받는데, 그 데이타를 임시로 저장해놓을 위치이다.

다음은 소프트맥스를 이용하여 모델을 정의합니다.

\# tf Graph Input  
 x = tf.placeholder\(tf.float32, \[**None**, 784\]\) \# mnist data image of shape 28\*28=784  
 y = tf.placeholder\(tf.float32, \[**None**, 10\]\) \# 0-9 digits recognition =&gt; 10 classes  
  
 \# Set model weights  
 W = tf.Variable\(tf.zeros\(\[784, 10\]\)\)  
 b = tf.Variable\(tf.zeros\(\[10\]\)\)  
  
 \# Construct model  
 pred = tf.nn.softmax\(tf.matmul\(x, W\) + b\) \# Softmax

x는 트레이닝 데이타를 저장하는 스테이크홀더, W는 Weight, b는 bias 값이고, 모델은 pred = tf.nn.softmax\(tf.matmul\(x, W\) + b\) 이 됩니다.

모델을 정의했으면 학습을 위해서, 코스트 함수를 정의합니다.

\# Minimize error using cross entropy  
 cost = tf.reduce\_mean\(-tf.reduce\_sum\(y\*tf.log\(pred\), reduction\_indices=1\)\)  
  
 \# Gradient Descent  
 optimizer = tf.train.GradientDescentOptimizer\(learning\_rate\).minimize\(cost\)

이 코스트 함수를 가지고 코스트가 최소화가 되는 W와 b를 구해야 하는데, 옵티마이져를 사용합니다. 여기서는 경사 하강법\(Gradient Descent Optimizer\)를 사용하였다.

GradientDescent에서 learning rate는 학습속도이다. 여기서는 0.1로 정하였다.

세션 초기화  

\# Initialize the variables \(i.e. assign their default value\)  
 init = tf.global\_variables\_initializer\(\)  
  
 \# Start training  
 **with** tf.Session\(\) **as** sess:  
     \# Run the initializer  
     sess.run\(init\)

tf.Session\(\) 을 이용해서 세션을 만들고, global\_variable\_initializer\(\)를 이용하여, 변수들을 모두 초기화한후, 초기화 값을 sess.run에 넘겨서 세션을 초기화 합니다.

세션이 생성되었으면 이제 트레이닝을 시작합니다.

**for** epoch **in** range\(100\):    \# 100번씩, 전체 데이타에서 100개씩 뽑아서 트레이닝을 함.  
     avg\_cost = 0.  
     total\_batch = int\(mnist.train.num\_examples/100\)  
     \# Loop over all batches  
     **for** i **in** range\(total\_batch\):  
         batch\_xs, batch\_ys = mnist.train.next\_batch\(100\)  
         \# Run optimization op \(backprop\) and cost op \(to get loss value\)  
         \_, c = sess.run\(\[optimizer, cost\], feed\_dict={x: batch\_xs, y: batch\_ys}\)  
         \# Compute average loss  
         avg\_cost += c / total\_batch  
     \# Display logs per epoch step  
     **if** \(epoch+1\) % 10 == 0:  
         print\(**"Epoch:"**, **'%04d'** % \(epoch+1\), **"cost="**, **"{:.9f}"**.format\(avg\_cost\)\)

결과값 출력

print\(**"Optimization Finished!"**\)  
 print\(**'b is '**, sess.run\(b\)\)  
 print\(**'W is'**, sess.run\(W\)\)

마지막으로 학습에서 구해진 W와 b를 출력해보자

다음은 실행 결과 스크린 샷이다.

Extracting /tmp/data/train-images-idx3-ubyte.gz

먼저 앞에서 데이타를 로딩하도록 지정한 디렉토리에, 학습용 데이타를 다운 받아서 압축 받는 것을 확인할 수 있습니다. 그 다음 학습이 끝난후에, b와 W 값이 출력되었습니다.

이제 모델을 만들고 학습을 시켰으니, 이 모델이 얼마나 정확하게 작동하는지를 테스트해보자.  mnist.test.image 와 mnist.test.labels 데이타셋을 이용하여 테스트를 진행하는데, 앞에서 나온 모델에 mnist.test.image 데이타를 넣어서 예측을 한 후에, 그 결과를 mnist.test.labels \(정답\)과 비교해서 정답률이 얼마나 되는지를 비교합니다.

다음은 모델 테스팅 코드이다. 이 코드를 위의 코드 뒤에 붙여서 실행하면 됩니다.

모델 검증 코드

\# Test model  
 correct\_prediction = tf.equal\(tf.argmax\(pred, 1\), tf.argmax\(y, 1\)\)  
 \# Calculate accuracy  
 accuracy = tf.reduce\_mean\(tf.cast\(correct\_prediction, tf.float32\)\)  
 print\(**"Accuracy:"**, accuracy.eval\({x: mnist.test.images, y: mnist.test.labels}\)\)

correct\_prediction = tf.equal\(tf.argmax\(y, 1\), tf.argmax\(y\_, 1\)\)

코드를 보자, tf.argmax 함수를 이해해야 하는데, argmax\(y,1\)은 행렬 y에서 몇번째에 가장 큰 값이 들어가 있는지를 리턴해주는 함수이다. 아래 예제 코드를 보면

session = tf.InteractiveSession\(\)

data = tf.constant\(\[9,2,11,4\]\)

idx = tf.argmax\(data,0\)

print idx.eval\(\)

session.close\(\)

\[9,2,11,4\] 에서 최대수는 11이고, 이 위치는 두번째 \(0 부터 시작합니다.\)이기 때문에 0을 리턴합니다. 두번째 변수는 어느축으로 카운트를 할것인지를 선택합니다. 1차원 배열의 경우에는 0을 사용합니다. 여기서 y는 2차원 행렬인데, 0이면 같은 열에서 최대값인 순서, 1이면 같은 행에서 최대값인 순서를 리턴합니다.

그럼 원래 코드로 돌아오면 tf.argmax\(y,1\)은 y의 각행에서 가장 큰 값의 순서를 찾는다. y의 각행을 0~9으로 인식한 이미지의 확률을 가지고 있습니다.

아래는 4를 인식한 y 값인데, 4의 값이 0.7로 가장높기 \(4일 확률이 70%, 3일 확률이 10%, 1일 확률이 20%로 이해하면 됩니다.\) 때문에, 4로 인식됩니다.

여기서 tf.argmax\(y,1\)을 사용하면, 행별로 가장 큰 값을 리턴하기 때문에, 위의 값에서는 4가 리턴이됩니다. 테스트용 데이타에서 원래 정답이 4로 되어 있다면, argmax\(y\_,1\)도 4를 리턴하기 때문에, tf.equal\(tf.argmax\(y, 1\), tf.argmax\(y\_, 1\)\)는 tf.equals\(4,4\)로 True를 리턴하게 됩니다.

모든 테스트 셋에 대해서 검증을 하고 나서 그 결과에서 True만 더해서, 전체 트레이닝 데이타의 수로 나눠 주면 결국 정확도가 나오는데, tf.cast\(boolean, tf.float32\)를 하면 텐서플로우의 bool 값을 float32 \(실수\)로 변환해줍니다. True는 1.0으로 False는 0.0으로 변환해줍니다. 이렇게 변환된 값들의 전체 평균을 구하면 되기 때문에, tf.reduce\_mean을 사용합니다.

이렇게 정확도를 구하는 함수가 정의되었으면 이제 정확도를 구하기 위해 데이타를 넣어보자

accuracy.eval\({x: mnist.test.images, y: mnist.test.labels}\)

x에 mnist.test.images 데이타셋으로 이미지 데이타를 입력받아서  y \(예측 결과\)를 계산하고, y\_에는 mnist.test.labels 정답을 입력 받아서, y와 y\_로 정확도 accuracy를 구해서 출력합니다. 최종 출력된 accuracy 정확도는 0.9272 로 대략 92% 정도가 나온다.

